---
title: "Unsupervised Learning in R"
author: "Camila Bezerra"
date: "10/09/2019"
output:
  html_document:
    theme: united
    highlight: monochrome
---

```{r, warning=F}
library(ggplot2)
library(tidyverse)
library(dplyr)
```

# 1. Introduction to Modeling

## Exploratory data analysis

Three basic steps to explanatory data analysis(EDA):

1. Looking at your data
2. Creating visualizations
3. Computing summary statics

## Exploratory visualization of age

```{r}
# Load packages
library(moderndive)
library(ggplot2)

# Plot the histogram
ggplot(evals, aes(x = age)) +
  geom_histogram(binwidth = 5) +
  labs(x = "age", y = "count")
```

## Numerical summaries of age

```{r}
# Load packages
library(moderndive)
library(dplyr)

# Compute summary stats
evals %>%
  summarise(mean_age = mean(age),
            median_age = median(age),
            sd_age = sd(age))
```

## Exploratory visualization of house size

```{r}
# Load packages
library(moderndive)
library(ggplot2)

# Plot the histogram
ggplot(house_prices, aes(x = sqft_living)) +
  geom_histogram() +
  labs(x = "Size (sq.feet)", y = "count")

## sqft_living is right-skewed.
```

## Log10 transformation of house size

```{r}
# Load packages
library(moderndive)
library(dplyr)
library(ggplot2)

# Add log10_size
house_prices_2 <- house_prices %>%
  mutate(log10_size = log10(sqft_living))

# Plot the histogram  
ggplot(house_prices_2, aes(x = log10_size)) +
 geom_histogram()+
  labs(x = "log10 size", y = "count")
```

## EDA of relationship of teaching & "beauty" scores

It seems the original scatterplot did suffer from overplotting since the jittered scatterplot reveals many originally hidden points. Most bty_avg scores range from 2-8, with 5 being about the center.

```{r}
# Plot the histogram
ggplot(evals, aes(bty_avg)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = "Beauty score", y = "count")

# Scatterplot
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_point() +
  labs(x = "beauty score", y = "teaching score")

# Jitter plot
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  labs(x = "beauty score", y = "teaching score")
```

## Correlation between teaching and "beauty" scores

```{r}
# Compute correlation
evals %>%
  summarize(correlation = cor(score, bty_avg))
```

## The modeling problem for prediction

### Difference between explanation and prediction

Key difference in modeling goals:

1. \textbf{Explanation}: We care about the form of \hat{f}(), in particular any values quantifying relations between y and x.
2. \textbf{Prediction:} We don't care so muchabout the form of \^f(), only that yields "good" predictions \hat{y} of y based on x.

## EDA of relationship of house price and waterfront

```{r}
# View the structure of log10_price and waterfront
house_prices %>%
  select(log10_price, waterfront) %>%
  glimpse()

# Plot 
ggplot(house_prices, aes(x = waterfront, y = log10_price)) +
  geom_boxplot() +
  labs(x = "waterfront", y = "log10 price")
```

## Predicting house price with waterfront

```{r}
# Calculate stats
house_prices %>%
  group_by(waterfront) %>%
  summarize(mean_log10_price = mean(log10_price), n = n())

# Prediction of price for houses without view of waterfront
10^(5.66)

# Prediction of price for houses with view of waterfront
10^(6.12)
```

# 2. Modeling with Basic Regression

## Plotting a "best-fitting" regression line

```{r}
# Load packages
library(ggplot2)
library(dplyr)
library(moderndive)

# Plot 
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_point() +
  labs(x = "beauty score", y = "score") +
  geom_smooth(method = "lm", se = FALSE)
```


## Fitting a regression with a numerical x

```{r}
# Load package
library(moderndive)

# Fit model
model_score_2 <- lm(score ~ bty_avg, data = evals)

# Output content
model_score_2

# Load package
library(moderndive)

# Fit model
model_score_2 <- lm(score ~ bty_avg, data = evals)

# Output regression table
get_regression_table(model_score_2)
```

## Making predictions using "beauty score"

```{r}
# Use fitted intercept and slope to get a prediction
y_hat <- 3.88 + 5 * 0.0670
y_hat

# Use fitted intercept and slope to get a prediction
y_hat <- 3.88 + 5 * 0.0670
y_hat

# Compute residual y - y_hat
4.7 - 4.215
```

## Computing fitted/predicted values & residuals

```{r}
# Fit regression model
model_score_2 <- lm(score ~ bty_avg, data = evals)

# Get regression table
get_regression_table(model_score_2)

# Get all fitted/predicted values and residuals
get_regression_points(model_score_2)

# Fit regression model
model_score_2 <- lm(score ~ bty_avg, data = evals)

# Get regression table
get_regression_table(model_score_2)

# Get all fitted/predicted values and residuals
get_regression_points(model_score_2) %>% 
  mutate(score_hat_2 = 3.88 + 0.067 * bty_avg)

# Use fitted intercept and slope to get a prediction
y_hat <- 3.88 + 5 * 0.0670
y_hat

# Compute residual y - y_hat
4.7 - 4.215
```


## Explaining teaching score with gender

```{r}

# Fit a regression model
model_score_3 <- lm(score ~gender, data = evals)

# Get a regression table
get_regression_table(model_score_3)

# Compute group means based on gender
evals %>% 
  group_by(gender) %>% 
  summarize(avg_score = mean(score))

# A different categorical explanatory variable: rank
evals %>% 
  group_by(rank) %>% 
  summarize( n = n())
```

## EDA of relationship of score and rank

The boxplot and summary statistics suggest that teaching get the highest scores while tenured professors get the lowest. However, there is clearly variation around the respective means.

```{r}
ggplot(evals, aes(x = rank, y = score)) +
  geom_boxplot() +
  labs(x = "rank", y = "score")

evals %>%
  group_by(rank) %>%
  summarise(n = n(), mean_score = mean(score), sd_score = sd(score))
```

## Fitting a regression with a categorical x

```{r}
# Fit regression model
model_score_4 <- lm(score ~ rank, data = evals)

# Get regression table
get_regression_table(model_score_4)

# teaching mean
teaching_mean <- 4.28

# tenure track mean
tenure_track_mean <- 4.28 - 0.13

# tenured mean
tenured_mean <- 4.28 - 0.145
```

## Predicting teaching score using gender

```{r}
evals %>% 
  group_by(gender) %>% 
  summarize(mean_score = mean(score), sd_score = sd(score))

# Fit regression model:
model_score_3 <- lm(score ~ gender, data = evals)

# Get information on each point
get_regression_point(model_score_3)
```

### Histogram of residuals

```{r}
# Fit regression model
model_score_3 <- lm(score ~ gender, data = evals)

# Get regression points
model_score_3_points <- get_regression_points(model_score_3)

# Plot residuals
ggplot(model_score_3_points, aes(x = residual)) +
  geom_histogram()+
  labs(x = "residuals", title = "Residuals from score ~ gender model")
```

## Visualizing the distribution of residuals

```{r}
# Calculate predictions and residuals
model_score_4_points <- get_regression_points(model_score_4)
model_score_4_points

# Plot residuals
ggplot(model_score_4_points, aes( x = residual)) +
  geom_histogram() +
  labs(x = "residuals", title = "Residuals from score ~ rank model")
```

## Explaining house price with year & size

Another important reason to perform EDA is to discard any potential outliers that are likely data entry errors. In our case, after removing an outlier, you can see a clear positive relationship between the number of bedrooms and price, as one would expect.

```{r}
# Create scatterplot with regression line
ggplot(house_prices, aes(x = bedrooms, y = log10_price)) +
  geom_point() +
  labs(x = "Number of bedrooms", y = "log10 price") +
  geom_smooth(method = "lm", se = FALSE)

# Remove outlier
house_prices_transform <- house_prices %>%
  filter(bedrooms != 33)

# Create scatterplot with regression line
ggplot(house_prices_transform, aes(x = bedrooms, y = log10_price)) +
  geom_point() +
  labs(x = "Number of bedrooms", y = "log10 price") +
  geom_smooth(method = "lm", se = FALSE)
```


## Fitting a regression

In this multiple regression setting, the associated effect of any variable must be viewed in light of the other variables in the model. In our case, accounting for the size of the house reverses the relationship of the number of bedrooms and price from positive to negative!

```{r}
# Fit model
model_price_2 <- lm(formula = log10_price ~ log10_size + bedrooms, 
                    data = house_prices)

# Get regression table
get_regression_table(model_price_2)

```


## Predicting house price using year & size

```{r}
# Fit regression model using formula on form: y ~ x1 + x2
model_price_1 <- lm(log10_price ~ log10_size + yr_built, data = house_prices)

# output regression table
get_regression_table(model_price_1)

# Make prediction 
5.38 + 0.913 * 3.07 - 0.00138 * 1980

# Convert back to original untransformed units: US dollars
10^(5.45051)

# Computing all predicted values and residuals

## Output point-by-point information
get_regression_points(model_price_1)

# Sum of squared residuals

## Output point-by-point information
get_regression_points(model_price_1)

## Square all residulas and sum them
get_regression_points(model_price_1) %>% 
  mutate(sq_residuals = residual^2) %>% 
  summarize(sum_sq_residuals = sum(sq_residuals))
```


## Making predictions using size and bedrooms

```{r}
# Make prediction in log10 dollars
2.69 + 0.941 * log10(1000) - 0.033 * 3

# Make prediction dollars
10 ^(5.414)
```

## Interpreting residuals

```{r}
# Automate prediction and residual computation
get_regression_points(model_price_2)

# Automate prediction and residual computation
get_regression_points(model_price_2) %>%
  mutate(sq_residuals = residual ^2) %>%
  summarize(sum_sq_residuals = sum(sq_residuals))
```

## Parallel slopes model

```{r}
# Fit model
model_price_4 <- lm(formula = log10_price ~ log10_size + waterfront, 
                    data = house_prices)

# Get regression table
get_regression_table(model_price_4)
```

## Predicting house price using size & condition

```{r}
# Get regression table
get_regression_table(model_price_4)

# Prediction for House A
10^(2.96 + 0.825* 2.9 + 0.322)

# Prediction for House B
10^(2.96 + 0.825*3.1)
```

## Automating predictions on "new" houses

```{r}
# View the "new" houses
new_houses_2

# Get predictions on "new" houses
get_regression_points(model_price_4, newdata = new_houses_2)

# View the "new" houses
new_houses_2

# Get predictions price_hat in dollars on "new" houses
get_regression_points(model_price_4, newdata = new_houses_2) %>% 
  mutate(price_hat = 10^log10_price_hat)
```

# 4 - Model Assessment and Selection

## Refresher: sum of squared residuals

```{r}
# Model 2
model_price_2 <- lm(log10_price ~ log10_size + bedrooms, 
                    data = house_prices)
points <- get_regression_points(model_price_2)
points
# Model 4
model_price_4 <- lm(log10_price ~ log10_size + waterfront, 
                    data = house_prices)

# Calculate squared residuals
get_regression_points(model_price_4) %>%
  mutate(sq_residuals = residual ^ 2) %>%
  summarize(sum_sq_residuals = sum(sq_residuals))
```

## Assessing model fit with R-squared

$$ R^2 = 1 - \frac{Var(residuals)}{Var(y)}  $$

## Computing the R-squared of a model

```{r}
# Fit model
model_price_2 <- lm(log10_price ~ log10_size + bedrooms,
                    data = house_prices)
                    
# Get fitted/values & residuals, compute R^2 using residuals
get_regression_points(model_price_2) %>%
  summarize(r_squared = 1 - var(residual) / var(log10_price))
```

## Comparing the R-squared of two models

```{r}
# Fit model_price_2
model_price_2 <- lm(log10_price ~ log10_size + bedrooms,
                    data = house_prices)

# Get fitted/values & residuals, compute R^2 using residuals
get_regression_points(model_price_2) %>%
  summarize(r_squared = 1 - var(residual) / var(log10_price))
  
# Fit model_price_4
model_price_4 <- lm(log10_price ~ log10_size + waterfront,
                    data = house_prices)

# Get fitted/values & residuals, compute R^2 using residuals
get_regression_points(model_price_4) %>%
  summarize(r_squared = 1 - var(residual) / var(log10_price))
```

## Assessing predictions with RMSE

```{r}
## Root mean squared error:
get_regression_points(model_price_1) %>% 
  mutate(sq_residuals = residual ^2) %>% 
  summarize(mse = mean(sq_residuals)) %>% 
  mutate(rmse = sqrt(mse))
```


## Computing the MSE & RMSE of a model

```{r}
# Get all residuals, square them, take the mean and square root
get_regression_points(model_price_2) %>%
  mutate(sq_residuals = residual^2) %>%
  summarize(mse = mean(sq_residuals)) %>% 
  mutate(rmse = sqrt(mse))
```

## Comparing the RMSE of two models

RMSE can be thought of as the 'typical' error a predicive model will make.

Since RMSE relates to error, the smaller the error, the better!

```{r}
# MSE and RMSE for model_price_2
get_regression_points(model_price_2) %>%
  mutate(sq_residuals = residual^2) %>%
  summarize(mse = mean(sq_residuals), rmse = sqrt(mean(sq_residuals)))
```


## Fitting model to training data

```{r}
# Set random number generator seed value for reproducibility
set.seed(76)

# Randomly reorder the rows
house_prices_shuffled <- house_prices %>% 
  sample_frac(size = 1, replace = FALSE)

# Train/test split
train <- house_prices_shuffled %>%
  slice(1:10000)
test <- house_prices_shuffled %>%
  slice(10001:21613)

# Fit model to training set
train_model_2 <- lm(formula = log10_price ~ log10_size + bedrooms, data = train)
```


## Predicting on test data

```{r}
# Make predictions on test set
get_regression_points(train_model_2, newdata = test)

# Compute RMSE
get_regression_points(train_model_2, newdata = test) %>% 
  mutate(sq_residuals = residual^2) %>%
  summarize(rmse = sqrt(mean(sq_residuals)))
```

